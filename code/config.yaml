PROJECT_NAME: "KLUE-Byungryool Jo"
SEED: 42

# PATH
Roberta-large_DIR: './Roberta-large'
TRAIN_PATH: "../dataset/train/train.csv"
TEST_PATH: "../dataset/test/test_data.csv"
OUTPUT_DIR: "./results"
LOGGING_DIR: "./logs"
MODEL_SAVE_DIR: "./RL_tapt_best_model"

# MODEL
MODEL_NAME: "klue/roberta-large"
PRETRAINED_MODEL_PATH: "./pretrained_roberta_large"
SAVE_MODEL_NUM: 5

# HYPERPARAMETERS
MAX_EPOCH: 3
LR: 2.0e-5
BATCH_SIZE: 32
WARMUP_STEP: 800
WEIGHT_DECAY: 0.2
TEST_SIZE: 0.2

# LOG
SAVING_STEP: 800
LOGGING_STEP: 800
EVAL_STEP: 800
STRATEGY: "steps" ### 추가부분
REPORT_TO: "wandb"
RUN_NAME: "roberta-large_TPE"
LOAD_Roberta-large_AT_END: True

#INFERENCE

INFERENCE_OUTPUT_PATH: './prediction/roberta-large_tpe.csv'
MODEL_PATHS:
  - './best_model_fold0'
  - './best_model_fold1'
  - './best_model_fold2'
  - './best_model_fold3'
  - './best_model_fold4'