PROJECT_NAME: "KLUE-Byungryool Jo"
SEED: 42

# PATH
BEST_MODEL_DIR: './Roberta-large'
TRAIN_PATH: "../dataset/train/train.csv"
TEST_PATH: "../dataset/test/test_data.csv"
OUTPUT_DIR: "./results"
LOGGING_DIR: "./logs"
MODEL_SAVE_DIR: "./best_model_tpe"

# MODEL
MODEL_NAME: "klue/roberta-large"
PRETRAINED_MODEL_PATH: "./pretrained_roberta_large"
SAVE_MODEL_NUM: 5

# HYPERPARAMETERS
MAX_EPOCH: 3
LR: 2.0e-5
BATCH_SIZE: 32
WARMUP_STEP: 800
WEIGHT_DECAY: 0.2
TEST_SIZE: 0.2


# LOG
SAVING_STEP: 800
LOGGING_STEP: 800
EVAL_STEP: 800
STRATEGY: "steps" ### 추가부분
REPORT_TO: "wandb"
RUN_NAME: "roberta-large_TPE"
LOAD_BEST_MODEL_AT_END: True

LOSS_FN : "CrossEntropyLoss"

MODEL_TYPE : "SpecialEntityBERT"