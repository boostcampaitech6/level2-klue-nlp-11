{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation(Subject-Object Swapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 단계: 모든 파일은 코드 확인 및 수정 후 실행할 것\n",
    "# 1. data_aug.ipynb -> 2. adding_special_token.ipynb -> 3. separate_dev_data.ipynb -> \n",
    "# 4. config.yaml 수정 -> 5. train.py -> 6. inference.py -> 7. ensemble.ipynb(4~7 k번 반복)\n",
    "\n",
    "# 노트북 파일을 dataset 폴더에서 code 폴더로 옮겼기에, 데이터 경로를 바꿔야 함\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋을 불러옵니다. 예시 데이터프레임 생성\n",
    "df = pd.read_csv('./train/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 라벨 종류를 가져옵니다.\n",
    "target_labels = ['org:member_of', 'per:children', 'per:parents']\n",
    "taret_labels_itself = ['per:other_family','per:colleagues','per:siblings','per:spouse']\n",
    "after_labels = ['org:members', 'per:parents', 'per:children']\n",
    "\n",
    "# 각 라벨에 대해 작업을 수행합니다.\n",
    "for label, afterlabel in zip(target_labels, after_labels):\n",
    "    # 1. 특정 label을 가진 엔티티의 내용을 복사합니다.\n",
    "    selected_rows = df[df['label'] == label].copy()\n",
    "\n",
    "    # 2. 해당 엔티티의 subject_entity, object_entity 내용을 swap합니다.\n",
    "    selected_rows['subject_entity'], selected_rows['object_entity'] = selected_rows['object_entity'], selected_rows['subject_entity']\n",
    "\n",
    "    # 3. 해당 엔티티의 label 값을 변경합니다.\n",
    "    selected_rows['label'] = afterlabel\n",
    "\n",
    "    # 4. 원래의 데이터에 덧붙입니다.\n",
    "    df = pd.concat([df, selected_rows], ignore_index=True)\n",
    "\n",
    "for label in taret_labels_itself:\n",
    "    # 1. 특정 label을 가진 엔티티의 내용을 복사합니다.\n",
    "    selected_rows = df[df['label'] == label].copy()\n",
    "\n",
    "    # 2. 해당 엔티티의 subject_entity, object_entity 내용을 swap합니다.\n",
    "    selected_rows['subject_entity'], selected_rows['object_entity'] = selected_rows['object_entity'], selected_rows['subject_entity']\n",
    "\n",
    "    # 4. 원래의 데이터에 덧붙입니다.\n",
    "    df = pd.concat([df, selected_rows], ignore_index=True)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "df.to_csv('./train/train_aug.csv', index=False)  # 원하는 출력 파일 경로와 이름 설정\n",
    "\n",
    "#df.to_csv(output_filename, index=False, sep='\\t', encoding='utf-8')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation(Low Case Label Copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./train/train_aug.csv')\n",
    "\n",
    "label_list = ['org:number_of_employees/members',\n",
    "               'per:place_of_residence',\n",
    "               'org:founded',\n",
    "               'org:dissolved',\n",
    "               'per:date_of_death',\n",
    "               'per:place_of_birth',\n",
    "               'per:place_of_death',]\n",
    "\n",
    "#selected_entities = df[df['label'].isin(label_list)]\n",
    "\n",
    "selected_entities = df[df['label'].isin(label_list)]\n",
    "combined_df = pd.concat([df, selected_entities], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('./train/train_aug_copy.csv', index=False)\n",
    "combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
