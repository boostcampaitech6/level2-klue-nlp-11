program: train.py
method: bayes
name: roberta-large
metric:
  goal: maximize
  name: eval/micro f1 score
parameters:
  learning_rate:
    distribution: uniform
    max: 1e-04
    min: 1e-05
  num_train_epochs:
    values:
      - 10
  per_device_eval_batch_size:
    values:
      - 8
      - 16
      - 32
  per_device_train_batch_size:
    values:
      - 8
      - 16
      - 32
  warmup_steps:
    distribution: uniform
    max: 1000
    min: 0
  weight_decay:
    distribution: uniform
    max: 0.05
    min: 0.01